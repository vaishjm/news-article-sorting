{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5089b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data Visualization \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Load Text Cleaning Pkgs and Transformers\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Load ML Pkgs\n",
    "# Estimators\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53c6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BBC News Train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2015f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vaishnavi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vaishnavi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vaishnavi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Vaishnavi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14116e",
   "metadata": {},
   "source": [
    "# Text preprocess and Tokenizatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dbbeea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    text = text.split()\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    text = [wordnet.lemmatize(word) for word in text if word not in set(stopwords.words('english'))]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b93b9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    text = re.sub(\"<br\\\\s*/?>\", \" \", text)\n",
    "    text = re.sub(\"[^a-zA-Z']\", \" \", text)\n",
    "    text = re.sub(\"-\", \" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95904cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    combo = []\n",
    "    for i in range(0,len(data)):\n",
    "        text = remove_special_characters(data['Text'][i])\n",
    "        text = text.lower()\n",
    "        text = lemmatize(text)\n",
    "        \n",
    "        combo.append(text)\n",
    "    data['Text_processed'] = pd.DataFrame(combo)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78d846f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "      <td>worldcom ex bos launch defence lawyer defendin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>german business confidence slide german busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "      <td>bbc poll indicates economic gloom citizen majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "      <td>lifestyle governs mobile choice faster better ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "      <td>enron boss payout eighteen former enron direct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>857</td>\n",
       "      <td>double eviction from big brother model caprice...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>double eviction big brother model caprice holb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>325</td>\n",
       "      <td>dj double act revamp chart show dj duo jk and ...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>dj double act revamp chart show dj duo jk joel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1590</td>\n",
       "      <td>weak dollar hits reuters revenues at media gro...</td>\n",
       "      <td>business</td>\n",
       "      <td>weak dollar hit reuters revenue medium group r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>1587</td>\n",
       "      <td>apple ipod family expands market apple has exp...</td>\n",
       "      <td>tech</td>\n",
       "      <td>apple ipod family expands market apple expande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>538</td>\n",
       "      <td>santy worm makes unwelcome visit thousands of ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>santy worm make unwelcome visit thousand websi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId                                               Text  \\\n",
       "0          1833  worldcom ex-boss launches defence lawyers defe...   \n",
       "1           154  german business confidence slides german busin...   \n",
       "2          1101  bbc poll indicates economic gloom citizens in ...   \n",
       "3          1976  lifestyle  governs mobile choice  faster  bett...   \n",
       "4           917  enron bosses in $168m payout eighteen former e...   \n",
       "...         ...                                                ...   \n",
       "1485        857  double eviction from big brother model caprice...   \n",
       "1486        325  dj double act revamp chart show dj duo jk and ...   \n",
       "1487       1590  weak dollar hits reuters revenues at media gro...   \n",
       "1488       1587  apple ipod family expands market apple has exp...   \n",
       "1489        538  santy worm makes unwelcome visit thousands of ...   \n",
       "\n",
       "           Category                                     Text_processed  \n",
       "0          business  worldcom ex bos launch defence lawyer defendin...  \n",
       "1          business  german business confidence slide german busine...  \n",
       "2          business  bbc poll indicates economic gloom citizen majo...  \n",
       "3              tech  lifestyle governs mobile choice faster better ...  \n",
       "4          business  enron boss payout eighteen former enron direct...  \n",
       "...             ...                                                ...  \n",
       "1485  entertainment  double eviction big brother model caprice holb...  \n",
       "1486  entertainment  dj double act revamp chart show dj duo jk joel...  \n",
       "1487       business  weak dollar hit reuters revenue medium group r...  \n",
       "1488           tech  apple ipod family expands market apple expande...  \n",
       "1489           tech  santy worm make unwelcome visit thousand websi...  \n",
       "\n",
       "[1490 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c2644291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_processed.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ced46b",
   "metadata": {},
   "source": [
    "# label the column 'Category' for learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7b948460",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# Encode labels in column 'Category'.\n",
    "df['Category_id']= label_encoder.fit_transform(df['Category'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1cb42caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df['Text_processed'],\n",
    "                                                 df['Category_id'],\n",
    "                                                test_size=0.20,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a6ab0036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1192,)\n",
      "(298,)\n",
      "(1192,)\n",
      "(298,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550a008",
   "metadata": {},
   "source": [
    "# tfidf Vectorizer for feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0cde0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ca41e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming train and text data seprately to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a5a6b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = tfidf.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "234d9272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192, 1000)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "09866c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst= tfidf.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b72d0825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 1000)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ab9af",
   "metadata": {},
   "source": [
    "# Different ML algorithms to train dataset and test accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1c66cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\",\n",
    "         \"Naive Bayes\", \"SVM \"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    MultinomialNB(),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0c553688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 0.24161073825503357 \n",
      "Decision Tree Accuracy: 0.19463087248322147 \n",
      "Random Forest Accuracy: 0.2348993288590604 \n",
      "Logistic Regression Accuracy: 0.28523489932885904 \n",
      "Naive Bayes Accuracy: 0.28859060402684567 \n",
      "SVM  Accuracy: 0.2684563758389262 \n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nlp_model=model\n",
    "    nlp_model.fit(X_trn,y_train)\n",
    "    y_pred = nlp_model.predict(X_tst)\n",
    "    test_accuracy  = accuracy_score(y_test, y_pred)\n",
    "    print('{} Accuracy: {} '.format(name, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the test data accuracy is too low -->> perform hyperparameter tuning on Logistic Regression , Naive Bayes ,SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49e3c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline choose best tfidf parameter with best ml classifier\n",
    "X = df['Text'][:1192]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da420b5",
   "metadata": {},
   "source": [
    "# svc pipeline model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14c1e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning of svm model  \n",
    "pipeline_svm = Pipeline([\n",
    "    ('vect', TfidfVectorizer( max_features=1000, stop_words='english' )),\n",
    "    ('svm', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dbe0931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_svm = {\n",
    "    \n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'svm__C': [0.1, 1, 10, 100, 1000],\n",
    "    'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'svm__kernel': ['rbf','linear']    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cdec0221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 150 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(lowercase=False,\n",
       "                                                        max_features=1000,\n",
       "                                                        stop_words='english')),\n",
       "                                       ('svm', SVC())]),\n",
       "             n_jobs=2,\n",
       "             param_grid={'svm__C': [0.1, 1, 10, 100, 1000],\n",
       "                         'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'svm__kernel': ['rbf', 'linear'],\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grid = GridSearchCV(pipeline_svm, parameters_svm, cv=2, n_jobs=2, verbose=3 ,scoring='accuracy')\n",
    "grid.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6bf33012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "Pipeline(steps=[('vect',\n",
      "                 TfidfVectorizer(lowercase=False, max_features=1000,\n",
      "                                 stop_words='english')),\n",
      "                ('svm', SVC(C=1, gamma=1))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set:\")\n",
    "print(grid.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f41ca9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 0.12751677852348994\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "print(\"SVM Test Accuracy: {}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9dff0",
   "metadata": {},
   "source": [
    "# LogisticRegression pipeline model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4a9be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    ('vect', TfidfVectorizer(max_features=1000)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "078a6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LogisticRegression solvers don't allow L1 penalty\n",
    "param_lr = {\n",
    "             \"classifier__penalty\": ['l2'],\n",
    "             \"classifier__C\": np.logspace(0, 4, 10),\n",
    "             \"classifier__solver\":['newton-cg','saga','sag','liblinear'], \n",
    "             \"vect__max_df\": (0.25, 0.5, 0.75),\n",
    "             \"vect__ngram_range\": [(1, 1), (1, 2), (1, 3)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbd2ca6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(max_features=1000)),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                         'classifier__penalty': ['l2'],\n",
       "                         'classifier__solver': ['newton-cg', 'saga', 'sag',\n",
       "                                                'liblinear'],\n",
       "                         'vect__max_df': (0.25, 0.5, 0.75),\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a gridsearch of the pipeline, the fit the best model\n",
    "gridsearch = GridSearchCV(pipe_lr, param_lr , cv=2, verbose=0,n_jobs=-1,scoring='accuracy') # Fit grid search\n",
    "gridsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "342782f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vect',\n",
      "                 TfidfVectorizer(max_df=0.5, max_features=1000,\n",
      "                                 ngram_range=(1, 2))),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=7.742636826811269, solver='newton-cg'))])\n",
      "Best parameters set:\n",
      "{'classifier__C': 7.742636826811269, 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg', 'vect__max_df': 0.5, 'vect__ngram_range': (1, 2)}\n",
      "Best Score:\n",
      "0.9672818791946309\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Best parameters set:\")\n",
    "print(gridsearch.best_params_)\n",
    "print(\"Best Score:\")\n",
    "print(gridsearch.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb6dc4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Test Accuracy: 0.9765100671140939\n"
     ]
    }
   ],
   "source": [
    "y_pred = gridsearch.predict(X_test)\n",
    "print(\"LogisticRegression Test Accuracy: {}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4705c334",
   "metadata": {},
   "source": [
    "# Naive Bayes pipeline model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "99e33f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mnb = Pipeline([\n",
    "    ('vect', TfidfVectorizer(max_features=1000)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ab6ddf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_mnb = {\n",
    "            'mnb__alpha': np.linspace(0.5, 1.5, 6),\n",
    "            'mnb__fit_prior': [True, False],\n",
    "            'vect__norm': [None, 'l1', 'l2'],\n",
    "             'vect__max_df': (0.25, 0.5, 0.75),\n",
    "             'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "efc60420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(max_features=1000)),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'mnb__alpha': array([0.5, 0.7, 0.9, 1.1, 1.3, 1.5]),\n",
       "                         'mnb__fit_prior': [True, False],\n",
       "                         'vect__max_df': (0.25, 0.5, 0.75),\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'vect__norm': [None, 'l1', 'l2']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a gridsearch of the pipeline, the fit the best model\n",
    "gridmnb = GridSearchCV(pipe_mnb, param_mnb , cv=2, verbose=0,n_jobs=-1,scoring='accuracy') # Fit grid search\n",
    "gridmnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d4a7c2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "{'mnb__alpha': 0.5, 'mnb__fit_prior': True, 'vect__max_df': 0.75, 'vect__ngram_range': (1, 3), 'vect__norm': 'l2'}\n",
      "Best Score:\n",
      "0.9614093959731544\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(gridmnb.best_params_)\n",
    "print(\"Best Score:\")\n",
    "print(gridmnb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f0defa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Test Accuracy: 0.9664429530201343\n"
     ]
    }
   ],
   "source": [
    "y_predmnb = gridmnb.predict(X_test)\n",
    "print(\"Naive Bayes Test Accuracy: {}\".format(accuracy_score(y_test,y_predmnb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e33f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d3132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b14ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
